{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYPD Allegations\n",
    "* **See the main project notebook for instructions to be sure you satisfy the rubric!**\n",
    "* See Project 03 for information on the dataset.\n",
    "* A few example prediction questions to pursue are listed below. However, don't limit yourself to them!\n",
    "    * Predict the outcome of an allegation (might need to feature engineer your output column).\n",
    "    * Predict the complainant or officer ethnicity.\n",
    "    * Predict the amount of time between the month received vs month closed (difference of the two columns).\n",
    "    * Predict the rank of the officer.\n",
    "\n",
    "Be careful to justify what information you would know at the \"time of prediction\" and train your model using only those features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "### Introduction\n",
    "In this project I will be building models to predict the ethnicity of complainants in the nypd dataset. Since ethnicity is a nominal categorical column, this is a classification problem. This will not be an easy task, since the responses in this dataset do not easily differentiate such ethnicites. It will be especially difficult to acheive a good accuracy (which will be our evaluation metric), since over 15% of complainant ethnicities are missing. Since we cannot just drop such a large chunk of data, we must incorporate missing data as an option (\"Unknown\") for the classifier to predict. Unfortunately, this can cause a lot of problems because we don't know the true distribution of the missing complainant ethnicities. The reason why this is so problematic is because there might be feature patterns common with a certain ethnicity that is also the true hidden ethnicity in allegations with missing complainant ethnicity. This means that the classifier might often predict \"Unknown\" instead of an actual ethnicity which might actually be a better prediction. Regardless, we will do our best to create a reliable classifier of complainant ethnicites. I will be using accuracy as the evaluation metric for this prediction problem because it will give us a basic understanding of how often the classifier predicted correctly. With the large obstacles and limitations described, the goal of the final model created is to produce an accuracy on the test set of 70%.\n",
    "\n",
    "It is worth noting that for this project, I used the cleaned version of this dataset, which was cleaned in project3. The following was done to clean the data. I started by looking through each column to see if missingness was explained in different ways. For example, in the shield_no column, missingness was usually defined as a shield_no of 0 instead of nans, since this is an integer column. Similarly, the precinct column contained an absurd amount of 0s and 1000s. This wouldn't make sense sicne there are not precincts with these numbers. If I had not filled these with nans, we might have seen much different results with our later analysis of NYC's precincts since there were so many precinct inputs of 0 and 1000. It was found that some of the complainant_ages were below 0, which also doesn't make sense. There were also \"Unknown\"s in the complainant_ethnicity column. For all of these cases, the mentioned observations were converted to nans. In order to retain the type of each of the integer columns, the columns were converted to type Int8 or Int16. Some of the complainant ages were found to be between ages 1 and 10. This wouldn't make much sense, since the age input should be that of the person filing the complaint. It is hard to imagine a child this young filing a formal complaint and more likely that the parent of a child filed it for them with the child's age (or that it was simply mistyped). For this reason, I was conservative and converted ages 8 and below to nans. Next, I added a few columns to the dataframe for potential future EDA/analysis. One of these columns added was the substantiated column. This column is a series of boolean which tells whether each allegation was found to be true or not. This column was useful in the hypotesis testing section, where it was tested whether or not there was a significant difference between guilty police demographics and demographics of NYPD police. It also proved useful in coming up for the idea of the question posed, since being accused of something is different from being guilty. Therefore, this was a crucial column that would help differentiate ethnicities of accused officers vs. guilty officers. Next, a column was added to aggregate the month/year columns into one for all-in-one access. This column did not end up being useful in analysis, since month of allegations weren't considered. EDA was focused mainly on inspecting the ethnicities and precincts of the data. Immediately after noticing how skewed the demographics for both complainant ethnicity and NYPD member ethnicity were, I knew this would be the focus of the project. With NYPD demographics, setup for a later hypothesis was done within the EDA section by pulling external NYPD demographics off a .gov site. With this and the demographics of recent allegations, a hypothesis test was ready to be done later down the line. The majority of the EDA section consisted of looking into the precinct data. Right off the bat, the 75th precinct had an extreme amount of allegations compared to the others. After taking population and substantiation rate into account before becoming suspicious of corruption, the precict still appeared extreme compared to the others. From here, this precinct was compared to other even more dangerous precincts using a metric that incorporated number of allegations per population times substantiation rate. This was the metric used because it normalizes by person and takes into account how many of the officers were found to be guilty of the claims against them. With these metrics, we're all set up for another hypothesis test (using a test that we haven't used in this class).\n",
    "### Baseline Model\n",
    "For my baseline model, I will be using 5 features. These features are officer ethnicity, precinct of incident, allegation, last name of complainant, and number of months before case was resolved by the review board. Officer ethnicity, precinct, allegation, and last name are all nominal categorical features, and will therefore all be OneHot-Encoded. This leaves Months Before Resolved, which is a discrete numerical feature. This feature will be standardized. After 20 runs of splitting the dataset into training and testing data, training the model, and finding the test accuracy, the mean of such accuracies was 0.667 (or 66.7%). This is not great, but considering we have accounted for overfitting (as described in the baseline model code), this is okay for our baseline. This is not great because the classifier is only correcting 2/3 times. However, when we remember that many of these incorrect predictions could be due to the \"Unknown\" ethnicity prediction, and that it is quite difficult to predict the correect ethnicity out of the 7 possible options, it doesn't seem so bad. Ideally, we will improve the model by 3% in our final model through feature engineering to achieve our goal of an average 70% accuracy on testing data.\n",
    "\n",
    "### Final Model\n",
    "In my final model, I first and foremost feature engineered a pipeline that would deal with uncommon responses in the dataset. There are several responses in the \"allegation\" and \"last_name\" columns that are different from more common responses. In other words, there are plently of responses in these columns with only 1 or 2 of those exact responses. The worry is that when these uncommon responses are OneHot-Encoded and the model is trained on them, the model will memorize these responses when making predictions and overfit as a result. Furthemore, the whole idea behind including these features is that a more common response pertains more to a certain ethnicity. A threshold of 3 responses was used. This means that in the entirety of the dataset, only last names and allegation responses with 3 or more collective responses would be kept. Responses below this threshold were converted to string \"IGNORE\", which would all be OneHot-Encoded into a single column. The second form of feature-engineering I included in my final model was the extraction of the board's decision for each allegtion. The board's decision (Substantiated, Unsubstantiated, or Exonnerated) could be an important predictor because there may be trends with each ethnicity telling of how frequently that ethnicity's claims led to the officer being punished. Since all of the possible responses in the board_disposition column contain the actual decision in the first word of the string, we could simply split() the string and extract the first word in the list to accomplish this. Once this function was written, the result was OneHot-Encoded and used in the final model. It is important to note that I decided to add complainant_gender into the final model as a feature. Gender could play a large part in trends we see within the characteristics of ethnicity groups in the dataset. I stuck with the DecisionTreeClassifier for my final model type because it ended up providing the best results in terms of accuracy. I did not include the testing of other model types in this notebook since GridSearching with them would have taken very long when opening the notebook from scratch. I tried KNeighbors Classifier with gridsearched n_neighbors 3,4,5,10,20 and RandomForest Classifier with the same gridsearch parameters as my DecisionTreeClassifier. The DecisionTree Classifier produced very similar accuracies to KNeighbors, so I went with the DecisionTreeClassifier since it is faster and is easier to understand wnen changing its parameters. The RandomForest Classifier took extremely long to run and also produced very similar accuracies. Unfortunately, with each GridSearch, we would receive the combination of parameters with the DecisionTree Classifier that would yeild the most amount of overfitting. These parameters were max_depth = None, min_samples_leaf = 2, and min_samples_split = 2. This combination of parameters allows for the most amount of decision trees creatable through the Decision Tree Classifier, since it is putting no limitations on it. We can imagine why these parameters would yield such different training and testing accuracies, since the classifier is almost memorizing the training set. When using these \"best\" parameters, the training accuracy was around 89%, while the testing accuracy was around 73%. This indicates clear overfitting. In order to reduce this overfitting, I fine tuned the Classifier's parameters to produce training and testing accuracies that were reasonably closer. I decided on the parameters: max_depth=75, min_samples_leaf=10, and min_samples_split=5. These parameters produced reasonably close accuracies of 72% (train accuracy) and 68% (test accuracy). Although our testing accuracy dropped slightly, it is more important that we had accounted for the overfitting of the Classifier, since it could be used on future nypd allegation data. Even though we barely missed our 70% testing accuracy goal, we've produced a transparent model that, with the limitations, does a decent job at predicting complainant ethnicites. \n",
    "\n",
    "### Fairness Evaluation\n",
    "The accuracy of the model on female complainants was evaluated to determine if the model is worse at predicting for this gender compared to the others. The motivation for permuation testing females comes from their underrepresentation in the dataset compared to males. I started by permutation testing the accuracy of the model on female complainants to see if there was a significant difference in its accuracy vs. other genders. I chose accuracy because this not a binary classification problem; there are multiple ethnicities that the Classifier can predict. After permutation testing the females subset, it was determined that the accuracy of females is significantly different from the accuracies of the other genders. Therefore, this model is not fair towards all genders. I recognize that the final model should definitely be further revised before using this model for any reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['unique_mos_id', 'first_name', 'last_name', 'command_now', 'shield_no',\n",
      "       'complaint_id', 'month_received', 'year_received', 'received mo/yr',\n",
      "       'month_closed', 'year_closed', 'closed mo/yr', 'command_at_incident',\n",
      "       'rank_abbrev_incident', 'rank_abbrev_now', 'rank_now', 'rank_incident',\n",
      "       'mos_ethnicity', 'mos_gender', 'mos_age_incident',\n",
      "       'complainant_ethnicity', 'complainant_gender',\n",
      "       'complainant_age_incident', 'fado_type', 'allegation', 'precinct',\n",
      "       'contact_reason', 'outcome_description', 'board_disposition',\n",
      "       'Substantiated', 'Months Before Resolved'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_mos_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>command_now</th>\n",
       "      <th>shield_no</th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>month_received</th>\n",
       "      <th>year_received</th>\n",
       "      <th>received mo/yr</th>\n",
       "      <th>month_closed</th>\n",
       "      <th>...</th>\n",
       "      <th>complainant_gender</th>\n",
       "      <th>complainant_age_incident</th>\n",
       "      <th>fado_type</th>\n",
       "      <th>allegation</th>\n",
       "      <th>precinct</th>\n",
       "      <th>contact_reason</th>\n",
       "      <th>outcome_description</th>\n",
       "      <th>board_disposition</th>\n",
       "      <th>Substantiated</th>\n",
       "      <th>Months Before Resolved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Ruiz</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>8409.0</td>\n",
       "      <td>42835</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>(7, 2019)</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Failure to provide RTKA card</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Report-domestic dispute</td>\n",
       "      <td>No arrest made or summons issued</td>\n",
       "      <td>Substantiated (Command Lvl Instructions)</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10007</td>\n",
       "      <td>John</td>\n",
       "      <td>Sears</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>5952.0</td>\n",
       "      <td>24601</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>(11, 2011)</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Discourtesy</td>\n",
       "      <td>Action</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>Moving violation summons issued</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10007</td>\n",
       "      <td>John</td>\n",
       "      <td>Sears</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>5952.0</td>\n",
       "      <td>24601</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>(11, 2011)</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Offensive Language</td>\n",
       "      <td>Race</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>Moving violation summons issued</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10007</td>\n",
       "      <td>John</td>\n",
       "      <td>Sears</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>5952.0</td>\n",
       "      <td>26146</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "      <td>(7, 2012)</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Question</td>\n",
       "      <td>67.0</td>\n",
       "      <td>PD suspected C/V of violation/crime - street</td>\n",
       "      <td>No arrest made or summons issued</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10009</td>\n",
       "      <td>Noemi</td>\n",
       "      <td>Sierra</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>24058.0</td>\n",
       "      <td>40253</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>(8, 2018)</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Force</td>\n",
       "      <td>Physical force</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Report-dispute</td>\n",
       "      <td>Arrest - other violation/crime</td>\n",
       "      <td>Substantiated (Command Discipline A)</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_mos_id first_name last_name command_now  shield_no  complaint_id  \\\n",
       "0          10004   Jonathan      Ruiz     078 PCT     8409.0         42835   \n",
       "1          10007       John     Sears     078 PCT     5952.0         24601   \n",
       "2          10007       John     Sears     078 PCT     5952.0         24601   \n",
       "3          10007       John     Sears     078 PCT     5952.0         26146   \n",
       "4          10009      Noemi    Sierra     078 PCT    24058.0         40253   \n",
       "\n",
       "   month_received  year_received received mo/yr  month_closed  ...  \\\n",
       "0               7           2019      (7, 2019)             5  ...   \n",
       "1              11           2011     (11, 2011)             8  ...   \n",
       "2              11           2011     (11, 2011)             8  ...   \n",
       "3               7           2012      (7, 2012)             9  ...   \n",
       "4               8           2018      (8, 2018)             2  ...   \n",
       "\n",
       "   complainant_gender complainant_age_incident           fado_type  \\\n",
       "0              Female                     38.0  Abuse of Authority   \n",
       "1                Male                     26.0         Discourtesy   \n",
       "2                Male                     26.0  Offensive Language   \n",
       "3                Male                     45.0  Abuse of Authority   \n",
       "4                 NaN                     16.0               Force   \n",
       "\n",
       "                     allegation precinct  \\\n",
       "0  Failure to provide RTKA card     78.0   \n",
       "1                        Action     67.0   \n",
       "2                          Race     67.0   \n",
       "3                      Question     67.0   \n",
       "4                Physical force     67.0   \n",
       "\n",
       "                                 contact_reason  \\\n",
       "0                       Report-domestic dispute   \n",
       "1                              Moving violation   \n",
       "2                              Moving violation   \n",
       "3  PD suspected C/V of violation/crime - street   \n",
       "4                                Report-dispute   \n",
       "\n",
       "                outcome_description                         board_disposition  \\\n",
       "0  No arrest made or summons issued  Substantiated (Command Lvl Instructions)   \n",
       "1   Moving violation summons issued                   Substantiated (Charges)   \n",
       "2   Moving violation summons issued                   Substantiated (Charges)   \n",
       "3  No arrest made or summons issued                   Substantiated (Charges)   \n",
       "4    Arrest - other violation/crime      Substantiated (Command Discipline A)   \n",
       "\n",
       "  Substantiated  Months Before Resolved  \n",
       "0          True                      10  \n",
       "1          True                       9  \n",
       "2          True                       9  \n",
       "3          True                      14  \n",
       "4          True                       6  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allegations = pd.read_csv(os.path.join(\"data\", \"cleaned_allegations.csv\"), index_col = 0)\n",
    "print(allegations.columns)\n",
    "allegations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering prediction of complainant_ethnicity with features: mos_ethnicity, allegation, first word in board_disposition, precinct, last name, months before resolved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first take a look at the missingness in our columns to see if we might need to impute, since our classifier will not work on missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_mos_id                  0\n",
      "first_name                     0\n",
      "last_name                      0\n",
      "command_now                    0\n",
      "shield_no                   5392\n",
      "complaint_id                   0\n",
      "month_received                 0\n",
      "year_received                  0\n",
      "received mo/yr                 0\n",
      "month_closed                   0\n",
      "year_closed                    0\n",
      "closed mo/yr                   0\n",
      "command_at_incident         1544\n",
      "rank_abbrev_incident           0\n",
      "rank_abbrev_now                0\n",
      "rank_now                       0\n",
      "rank_incident                  0\n",
      "mos_ethnicity                  0\n",
      "mos_gender                     0\n",
      "mos_age_incident               0\n",
      "complainant_ethnicity       5505\n",
      "complainant_gender          4195\n",
      "complainant_age_incident    4829\n",
      "fado_type                      0\n",
      "allegation                     1\n",
      "precinct                      48\n",
      "contact_reason               199\n",
      "outcome_description           56\n",
      "board_disposition              0\n",
      "Substantiated                  0\n",
      "Months Before Resolved         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33358"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(allegations.isna().sum())\n",
    "allegations.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we notice is that the response we want to predict with our classifier, \"complainant_ethnicity\", has an enourmous amount of missing values. In most cases, we would attempt to impute such a column based on its type of missingness. However, as explained after investigation in my project3, it would be unethical to impute this one. Incorrectly imputing a complainant's ethnicity could create problems of misrepresentation in allegations and make many assumptions, when in reality, each allegation has many factors and potential confounders. Unfortunately, it is possible that dropping such a large amount of observations might bias the complainant ethnicity predictions. I theororize that the majority of the allegations with missing complainant ethnicities are minorities, who, when filing a complaint, don't want their ethnicity taken into account (NMAR). This would be completely rational given the absurd amount of unpunished attrocities committed by police against minorities in the US. Rather than imputing or dropping these missing ethnicities, we will instead fill the missing ethnicites with an \"Unknown\" category. In other words, we will include missing ethnicities as an option for classification for the model. This makes sense because there could perhaps be combinations of features, rather than *just* an ethnicity being missing because of the value of itself, that contribute to the complainant leaving their ethnicity unfilled. In other words, with my theory that the label of one's ethnicity is the primary motivating factor in leaving such response blank, it is possible that other factors within the context of the allegation have furthered this motivation (and therefore made the complainant more likely to leave out their ethnicity). I'm hopeful that if the right features and parameters are passed into the chosen classifier, the classifier will successfully predict these observations as \"Unknown\". If my before stated theory is true, we might see the classifier predict many of the observations with missing ethnicities as minority ethnicities, since they would share patterns in feature responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Black              17114\n",
       "Hispanic            6424\n",
       "White               2783\n",
       "Other Race           677\n",
       "Asian                532\n",
       "Refused              259\n",
       "American Indian       64\n",
       "Name: complainant_ethnicity, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allegations[\"complainant_ethnicity\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see within the complainant_ethnicity responses that 259 complainants responded with \"Refused\". Since these ethnicities are also consdidered unknown, we will consider them \"Unknown\" for classification, as we will do for the missing (nan) ethnicities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allegations[\"complainant_ethnicity\"] = allegations[\n",
    "    \"complainant_ethnicity\"].fillna(\"Unknown\")\n",
    "allegations[\"complainant_ethnicity\"] = allegations[\n",
    "    \"complainant_ethnicity\"].str.replace(\"Refused\", \"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is only one missing \"allegation\" response and 48 missing \"precinct\" responses in our dataset of over 33,000 responses, let's elect to drop these allegations from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allegations = allegations.dropna(subset = [\"allegation\", \"precinct\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start building our model. We will start by including ethnicity of accused officer, precinct that incident took place in, what the allegation was, last name of the complainant, and number of months it took to resolve the complaint filed. We consider the ethnicity of the accused officer since, in many cases, misconduct of officers are racially motivated. With this in mind, the ethnicity of the complainant may be more likely to be a minority if the officer's ethnicity was White (this is just one example). Precinct should also be considered as a feature for two reasons. Firsly, different precincts have different demographics, which means (at least slightly) different proportions of ethnicities filing complaints. Secondly, as seen in my project3, different precincts have much more corruption than others, being that they're all under different leadership. The allegation column might be useful because certain allegations might be more common among certain ethnicities. For example, Hate Speech might be more common amongst minority accusers. I feel that last name will be a good predictor of complainant ethnicity, since there are more common last names for each ethnicity. Lastly, the amount of months an accusation took to be resolved might be a useful feature. My reasoning behind using this column in the model is that when an accuser's race is a factor in a case, it could be considered an additional factor in the case potentially requiring further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with the mos_ethnicity, precinct, allegation, and last_name columns, we can OneHot-Encode since these are categorical columns. We can then standardize the Months Before Resolved column. Once we manipulate our features in these ways, we'll use a Decision Tree Classifier. Before actually fitting the model, we will use GridSearchCV to find the best parameters for our model (specifically mex_depth, min_samples_leaf, and min_samples_split). Within GridSearchCV, we will set cv = 10 since our data spans many decades, and many associations can change over such long periods of time. Once we determine the best parameters, we will fit our model using these parameters within our classifier. Lastly, we will find our training and testing accuracies after splitting our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OHE pipeline for mos_ethnicity, allegation, precinct\n",
    "ohe = Pipeline([(\"other_OHE\", OneHotEncoder(\n",
    "    handle_unknown='ignore'))])\n",
    "\n",
    "#Standardize pipeline for Months Before Resolved\n",
    "stdscalar = Pipeline([(\"stdscalar\", StandardScaler())])\n",
    "\n",
    "#column transform to OHE and classify\n",
    "transformer = ColumnTransformer([\n",
    "    (\"ohe\", ohe, [\"mos_ethnicity\", \"precinct\", \"allegation\", \"last_name\"]),\n",
    "    (\"standardize\", stdscalar, [\"Months Before Resolved\"])\n",
    "])\n",
    "\n",
    "#GridSearch parameters\n",
    "parameters = {\n",
    "    'max_depth': [2,5,10,None],\n",
    "    'min_samples_split':[2,3,5,7],\n",
    "    'min_samples_leaf':[2,3,5,7]\n",
    "}\n",
    "\n",
    "gridsearch = Pipeline([\n",
    "    (\"transform\", transformer),\n",
    "    (\"gridsearch\", GridSearchCV(DecisionTreeClassifier(),\n",
    "                                parameters, cv = 10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
    "    allegations.drop([\"complainant_ethnicity\"], axis = 1),\n",
    "    allegations[\"complainant_ethnicity\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gridearch to find best features\n",
    "gridsearch.fit(Xtrain, Ytrain).named_steps[\"gridsearch\"].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from seeing these best parameters that we will probably see some overfitting in using these, since this combination of parameters allow for almost the most amount of branches and divisions in our tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Pipeline([\n",
    "    (\"transform\", transformer),\n",
    "    (\"classify\", DecisionTreeClassifier(\n",
    "        max_depth=None, min_samples_leaf=2, min_samples_split=2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8868165271888018\n",
      "0.7499249474632242\n"
     ]
    }
   ],
   "source": [
    "model1.fit(Xtrain, Ytrain)\n",
    "print(model1.score(Xtrain, Ytrain))\n",
    "print(model1.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we see that using these \"best parameters\" lead to overfitting (a large difference in the accuracy of our training and testing data), let's see if we can get our accuracies closer together by fine-tuning the DecisionClassifier's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set accuracy: 0.6975269261080047\n",
      "test set accuracy: 0.6693185229660763\n"
     ]
    }
   ],
   "source": [
    "#try new parameters to reduce overfitting\n",
    "model1 = Pipeline([\n",
    "    (\"transform\", transformer),\n",
    "    (\"classify\", DecisionTreeClassifier(\n",
    "        max_depth=75, min_samples_leaf=10, min_samples_split=5))\n",
    "])\n",
    "\n",
    "model1.fit(Xtrain, Ytrain)\n",
    "print(\"train set accuracy:\", model1.score(Xtrain, Ytrain))\n",
    "print(\"test set accuracy:\", model1.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though our training accuracy has dropped significatly, we know that we are not overfitting nearly as much anymore with our training and testing accuracies pretty close together. Unfortunately, our test accuracy did drop a little bit too, but this is a necessary tradeoff considering how different our two accuracies were previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that seems appropriate to feature-engineer for this model is a function that will account for responses that we don't commonly see in columns. For example, in the \"allegation\" column, we see some common responses like \"Assault\", but not many very specific responses like \"Questioned immigration status\". Having these very specific responses may lead to overfitting, which is why I want to incorporate this function. Responses with under 3 total responses will be converted to a string \"IGNORE\". Since the column passed into this function will be OneHot-Encoded after, the responses under the 3 threshold will be encoded into a single column designated for special, uncommon responses. Since there are also many unique last names, this column will be passed into the function as well before being OneHot-Encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unsubstantiated                             15427\n",
       "Exonerated                                   9601\n",
       "Substantiated (Charges)                      3790\n",
       "Substantiated (Formalized Training)          1033\n",
       "Substantiated (Command Discipline A)          962\n",
       "Substantiated (Command Discipline)            851\n",
       "Substantiated (Command Discipline B)          784\n",
       "Substantiated (Command Lvl Instructions)      452\n",
       "Substantiated (Instructions)                  247\n",
       "Substantiated (No Recommendations)            161\n",
       "Substantiated (MOS Unidentified)                1\n",
       "Name: board_disposition, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allegations[\"board_disposition\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second form of feature-engineering I will include in my final model is extracting the disposition of the board from each case. Since the first string of each of the decisions made by the board about accusations inform us of the outcome, we can extract this string and include it as a feature. In order to do this, we will write a function that splits each observation and gets the first string of the list. This might serve as a useful predictor of complainant ethnicity since the review board might have racial biases. It is also possible that certain ethnicites have higher substantiation rates than others. All features from the previous model will be included in this final model. A GridSearchCV will be used with this model to search for the best parameters to use in our Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to remove special responses\n",
    "def remove_unique(df):\n",
    "    threshold = 3\n",
    "    col_dict = {}\n",
    "    def determination(val):\n",
    "        try:\n",
    "            obs_above_thresh[val]\n",
    "            return val\n",
    "        except:\n",
    "            return \"IGNORE\"\n",
    "    for col in df:\n",
    "        obs_above_thresh = df[col].value_counts()[\n",
    "            (df[col].value_counts() >= threshold)].to_dict()\n",
    "        col_dict[col] = df[col].apply(determination)\n",
    "\n",
    "    return pd.DataFrame(col_dict)\n",
    "\n",
    "#remove unique responses and OHE features\n",
    "ohe_exclude = Pipeline([(\"exclude\", FunctionTransformer(remove_unique)),\n",
    "                        (\"OHE\", OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#extract first word in board_disposition and OHE\n",
    "def extract_disposition(df):\n",
    "    return pd.DataFrame(\n",
    "        df[\"board_disposition\"].str.split().apply(lambda lst: lst[0]))\n",
    "\n",
    "disposition_ohe = Pipeline([\n",
    "    (\"disposition_summarized\", FunctionTransformer(extract_disposition)),\n",
    "    (\"disposition_OHE\", OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#include feature-engineering in final model\n",
    "transformer2 = ColumnTransformer([\n",
    "    (\"disposition\", disposition_ohe, [\"board_disposition\"]),\n",
    "    (\"ohe_excl\", ohe_exclude, [\"allegation\", \"last_name\"]),\n",
    "    (\"ohe\", ohe, [\"mos_ethnicity\", \"precinct\", \"complainant_gender\"]),\n",
    "    (\"standardize\", stdscalar, [\"Months Before Resolved\"])\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [2,5,10,None], \n",
    "    'min_samples_split':[2,3,5,7],\n",
    "    'min_samples_leaf':[2,3,5,7]\n",
    "}\n",
    "\n",
    "gridsearch = Pipeline([\n",
    "    (\"transform\", transformer2),\n",
    "    (\"gridsearch\", GridSearchCV(\n",
    "        DecisionTreeClassifier(), parameters, cv = 10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
    "    allegations.drop([\"complainant_ethnicity\"], axis = 1),\n",
    "    allegations[\"complainant_ethnicity\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Once again, Gridsearch to find best set of parameters\n",
    "gridsearch.fit(Xtrain, Ytrain).named_steps[\"gridsearch\"].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set accuracy: 0.9078695537959245\n",
      "test set accuracy: 0.7377664365055538\n"
     ]
    }
   ],
   "source": [
    "model2 = Pipeline([\n",
    "    (\"transform\", transformer2),\n",
    "    (\"classify\", DecisionTreeClassifier(\n",
    "        max_depth=None, min_samples_leaf=2, min_samples_split=2))\n",
    "])\n",
    "\n",
    "model2.fit(Xtrain, Ytrain)\n",
    "print(\"train set accuracy:\", model2.score(Xtrain, Ytrain))\n",
    "print(\"test set accuracy:\", model2.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we once again see some of the infamous overfitting parameters producing far different accuracies, we will again tune the parameters to what seem best without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set accuracy: 0.722670469471235\n",
      "test set accuracy: 0.6844791353947763\n"
     ]
    }
   ],
   "source": [
    "model2 = Pipeline([\n",
    "    (\"transform\", transformer2),\n",
    "    (\"classify\", DecisionTreeClassifier(\n",
    "        max_depth=75, min_samples_leaf=10, min_samples_split=5))\n",
    "])\n",
    "\n",
    "model2.fit(Xtrain, Ytrain)\n",
    "print(\"train set accuracy:\", model2.score(Xtrain, Ytrain))\n",
    "print(\"test set accuracy:\", model2.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since complainant gender is now a feature in our model, I would like to investigate whether predictions are worse on female complainants, as opposed to any other gender. In order to do this, the accuracy will be compared. My strategy is to use accuracy as my test statistic to see if the accuracies are significantly different. Females are somewhat underrepresented in the data compared to males as we can see below. If the accuracy does end up being significantly lower (one-sided) for females, this model should not be viewed as fair and usable. Further modifications, including addition/removal of features, or switching to a different classifier would need to be considered before using this model for purposes other than this project. The null hypothesis is that my model is fair and that the accuracy for female is approximately equal to the accuracies of the other genders. The alternate hypothesis is that my model is not fair and the accuracy for female is not approximately equal to the accuracies of the other genders. A significance level of 0.05 will be used for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male                     24039\n",
       "Female                    5016\n",
       "Not described               57\n",
       "Transwoman (MTF)            20\n",
       "Transman (FTM)               5\n",
       "Gender non-conforming        2\n",
       "Name: complainant_gender, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allegations[\"complainant_gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null Hypothesis: \n",
    "My model is fair; the accuracy for female is approximately equal to the accuracies of the other genders\n",
    "\n",
    "Alternate Hypothesis: \n",
    "My model is not fair; the accuracy for female is not approximately equal to the accuracies of the other genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conduct permutation test\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
    "    allegations.drop([\"complainant_ethnicity\"], axis = 1),\n",
    "    allegations[\"complainant_ethnicity\"], test_size=0.2)\n",
    "model2.fit(Xtrain, Ytrain)\n",
    "\n",
    "#Put together test data to subset by Female\n",
    "concat = pd.concat([Xtest, Ytest], axis = 1)\n",
    "females = concat[concat[\"complainant_gender\"] == \"Female\"]\n",
    "\n",
    "#Find accuracy of model on Female subset\n",
    "femaleobs = model2.score(females.drop([\"complainant_ethnicity\"], axis = 1),\n",
    "    females[\"complainant_ethnicity\"])\n",
    "\n",
    "#Permute complainant_gender column and subset to compute shuffled gender accuracy\n",
    "scores = []\n",
    "n_trials = 1000\n",
    "for trial in range(n_trials):\n",
    "    permuted = concat.assign(shuffled = np.random.permutation(\n",
    "        concat[\"complainant_gender\"]))\n",
    "    shuffled_female = permuted[permuted[\"shuffled\"] == \"Female\"]\n",
    "    scores.append(model2.score(\n",
    "        shuffled_female.drop([\"complainant_ethnicity\"], axis = 1),\n",
    "        shuffled_female[\"complainant_ethnicity\"]))\n",
    "    \n",
    "#How often do we see a accuracy this low\n",
    "np.count_nonzero(femaleobs >= scores) / n_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a p-value of approximately 0, we reject the null hypothesis. Therefore, the final model is not fair; the accuracy for female is not approximately equal to the accuracies of the other genders. This model should definitely be further revised before considering using this model for any reason other than this project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
